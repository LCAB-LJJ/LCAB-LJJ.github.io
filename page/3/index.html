<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"lcab-ljj.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="热爱AIGC技术的博主，为您带来优质内容">
<meta property="og:type" content="website">
<meta property="og:title" content="AIGC-platform">
<meta property="og:url" content="https://lcab-ljj.github.io/page/3/index.html">
<meta property="og:site_name" content="AIGC-platform">
<meta property="og:description" content="热爱AIGC技术的博主，为您带来优质内容">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="进击的胖虎">
<meta property="article:tag" content="人工智能">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://lcab-ljj.github.io/page/3/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/3/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>AIGC-platform</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">AIGC-platform</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">AIGC</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="进击的胖虎"
      src="/%5Cimages%5C%E5%A4%B4%E5%83%8F.jpg">
  <p class="site-author-name" itemprop="name">进击的胖虎</p>
  <div class="site-description" itemprop="description">热爱AIGC技术的博主，为您带来优质内容</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">23</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://lcab-ljj.github.io/2024/07/18/PVG/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/%5Cimages%5C%E5%A4%B4%E5%83%8F.jpg">
      <meta itemprop="name" content="进击的胖虎">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AIGC-platform">
      <meta itemprop="description" content="热爱AIGC技术的博主，为您带来优质内容">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AIGC-platform">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/07/18/PVG/" class="post-title-link" itemprop="url">PVG！以小博大</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-07-18 15:36:56" itemprop="dateCreated datePublished" datetime="2024-07-18T15:36:56+08:00">2024-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-07 10:10:00" itemprop="dateModified" datetime="2024-08-07T10:10:00+08:00">2024-08-07</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p><strong>【重要】推荐使用 Wildcard虚拟信用卡订阅GPT、Onlyfans等服务，价格更便宜、卡片有效期更长、支持的服务更多，具体教程请查看：<a href="https://lcab-ljj.github.io/2024/08/07/Wildcard/">Wildcard教程</a></strong></p>
</blockquote>
<hr>
<p>OpenAI于2024年7月18日凌晨发布了最新的技术研究——Prover-Verifier-Games（简称“PVG”），旨在解决AI模型的“黑盒”问题，提升其推理和输出准确性。该技术通过引入一种新的训练框架，使用<strong>小模型</strong>来验证和监督<strong>大模型</strong>的输出，从而提高整体的输出准确率和可控性。</p>
<p>具体来说，PVG框架包含两个主要组成部分：证明者（Prover）和验证者（ Verifier）。其中，证明者通常是一个更强大的模型，如GPT-4；而验证者则是一个相对较小且能力较弱的模型，如GPT-3。在这一过程中，证明者需要生成易于验证的解决方案，而验证者则负责检查这些解决方案的正确性。</p>
<p><img src="/images/loading.png" data-original="/images/pvg1.jpg"></p>
<p>这种博弈论框架不仅提高了语言模型输出的可读性和可验证性，还使得这些输出更容易被人类理解和评估。此外，这种方法也增强了模型的安全性和准确性，特别是在法律、金融和营销等对安全性和准确性要求极高的领域中。</p>
<p>实际上，PVG（Proof-Verifier Game）技术理念在2021年8月的一篇学术论文中已初露端倪，激发了OpenAI的创新灵感。这一技术框架根植于博弈论，通过模拟证明者（Prover）与验证者（Verifier）之间的交互博弈，旨在提升机器学习模型生成内容的准确性和质量。</p>
<p>在此机制下，证明者的核心职责是创造性地生成内容，而验证者则扮演着批判性评估的角色，负责判断这些内容的真实性与合理性。PVG的核心策略在于通过多轮次的迭代训练，不断强化证明者与验证者的能力。每轮训练中，验证者首先运用监督学习技术，从历史证明者生成的内容样本中，学习如何准确识别正确信息，增强辨别能力。</p>
<p>随后，证明者则借助强化学习策略，不断优化其生成策略，力求生成的内容既准确无误，又能有效说服验证者接受。这一过程中，证明者与验证者形成了紧密相依的关系，证明者需不断提升生成内容的说服力，而验证者则需持续精进其判别能力。</p>
<p>为了进一步提升训练效率与效果，OpenAI在PVG框架内引入了两种强化类型的证明者角色：有益证明者（Helpful Prover）与狡猾证明者（Sneaky Prover）。前者致力于生成既正确又具说服力的内容，以正面促进学习过程；后者则试图通过生成错误但极具迷惑性的内容，挑战验证者的判断力，从而促使验证者发展出更高的鲁棒性和准确性。</p>
<p><img src="/images/loading.png" data-original="/images/pvg2.jpg"></p>
<p>以实际案例为例，当面对复杂问题时（如涉及多步骤逻辑推理的数学问题），GPT-4等先进模型能够给出准确答案（如肖娜父亲年龄的解答），而验证者模型（如GPT-3）则需经历多轮验证，从阿莉亚的年龄出发，逐步推导出肖娜及其父亲的年龄，确保每一步推理的正确性。</p>
<p>此外，OpenAI还引入了“可检查性训练”方法，通过交替训练验证器与证明者模型，不仅增强了验证器对过往证明者生成解决方案的监督预测能力，还促使证明者根据验证器的反馈和解决方案的正确性进行持续自我优化。随着训练轮次的增加，验证器对狡猾证明者生成的错误信息的抵抗力显著增强，同时有益证明者生成的内容也变得更加清晰易懂，更贴近人类理解模式。</p>
<p>然而，值得注意的是，高效训练验证者模型依赖于大量真实、准确的标签数据，以确保其辨别能力的精准性。若验证模型本身存在偏差，仍有可能导致验证结果的非预期输出。因此，在推进PVG技术发展的过程中，持续优化数据质量与验证机制同样重要。</p>
<hr>
<p>你好！我是<strong>进击的胖虎</strong>，一名关注AIGC技术的博主，如果你也喜欢我的文章就看看博主其他文章博主宝藏小站，开通正版GPT-4o教程在<a href="https://lcab-ljj.github.io/2024/08/07/Wildcard/"><strong>【重要】wildcard使用教程？如何用wildcard订阅国外服务？</strong></a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://lcab-ljj.github.io/2024/07/18/Sora/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/%5Cimages%5C%E5%A4%B4%E5%83%8F.jpg">
      <meta itemprop="name" content="进击的胖虎">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AIGC-platform">
      <meta itemprop="description" content="热爱AIGC技术的博主，为您带来优质内容">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AIGC-platform">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/07/18/Sora/" class="post-title-link" itemprop="url">【2024最新】4000字搞懂sora！一张脑图贯穿！</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-07-18 11:57:45" itemprop="dateCreated datePublished" datetime="2024-07-18T11:57:45+08:00">2024-07-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-07 10:09:55" itemprop="dateModified" datetime="2024-08-07T10:09:55+08:00">2024-08-07</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p><strong>【重要】推荐使用 Wildcard虚拟信用卡订阅GPT、Onlyfans等服务，价格更便宜、卡片有效期更长、支持的服务更多，具体教程请查看：<a href="https://lcab-ljj.github.io/2024/08/07/Wildcard/">Wildcard教程</a></strong></p>
</blockquote>
<hr>
<p>话不多说，上图！</p>
<p><img src="/images/loading.png" data-original="/images/%E8%84%91%E5%9B%BE.jpg"></p>
<p>博主到处查阅资料，凭借我自己的看法结合实际，下面就是对<strong>sora</strong>的具体阐释：</p>
<p>Sora是OpenAI推出的一款革命性的视频生成模型，能够根据文本指令、静态图像或视频生成长达60秒的完整视频。这一模型基于扩散式模型和自注意力深度学习机制，通过将视频片段转换为静态图像并去除噪音以达到清晰效果。</p>
<h1 id="1-核心技术与功能"><a href="#1-核心技术与功能" class="headerlink" title="1.核心技术与功能"></a>1.核心技术与功能</h1><h2 id="1-技术架构："><a href="#1-技术架构：" class="headerlink" title="1.技术架构："></a>1.技术架构：</h2><ul>
<li>Sora结合了Diffusion和Transformer技术，并融合了Google的MAGViT和DeepMind的NaViT等方案，应用了OpenAI DALL-E 3图像描述方案。</li>
<li>使用独特的CLIP模型架构，能够生成高质量的视频描述。</li>
<li>基于Transformer架构的扩散模型，可以灵活地扩展视频内容，改变风格和背景环境。</li>
</ul>
<h2 id="2-视频生成能力："><a href="#2-视频生成能力：" class="headerlink" title="2.视频生成能力："></a>2.视频生成能力：</h2><ul>
<li>能够生成高度细致的场景、复杂的多角度镜头以及富有情感的角色。</li>
<li>具备3D一致性、远距离相干性和物体持久性等模拟功能。</li>
<li>可以实现对复杂物理运动和逻辑关系的准确捕捉，尽管目前仍存在一些局限性。</li>
</ul>
<h2 id="3-应用范围："><a href="#3-应用范围：" class="headerlink" title="3.应用范围："></a>3.应用范围：</h2><ul>
<li>Sora在短视频、宣传片、动画电影等领域具有广泛的应用前景。</li>
<li>对广告业、电影预告片和短视频行业带来巨大影响，甚至可能颠覆这些行业。</li>
<li>在传媒领域推动智媒的发展，丰富元宇宙、长短视频和MR应用生态。</li>
</ul>
<h1 id="2-商业潜力与挑战"><a href="#2-商业潜力与挑战" class="headerlink" title="2.商业潜力与挑战"></a>2.商业潜力与挑战</h1><h2 id="1-商业化潜力："><a href="#1-商业化潜力：" class="headerlink" title="1.商业化潜力："></a>1.商业化潜力：</h2><p>Sora展现出明确的商业化潜力与应用路线，预计到2030年，全球&#x2F;中国相关市场复合增长率将达45%&#x2F;87%。<br>将进一步加深和拓宽OpenAI的护城河，少数巨头将占据底层算法和模型的主导地位。</p>
<h2 id="2-技术缺陷与挑战："><a href="#2-技术缺陷与挑战：" class="headerlink" title="2.技术缺陷与挑战："></a>2.技术缺陷与挑战：</h2><ul>
<li>目前Sora在处理复杂物理运动或逻辑关系时可能存在局限性，例如混淆文字表达或不符合现实世界的物理关系认知等。</li>
<li>需要更丰富的数据和更强的算力来优化其性能。</li>
<li>存在监管难题和版权、隐私等问题，需要与各方合作确保安全使用。</li>
</ul>
<h1 id="3-行业影响与未来趋势"><a href="#3-行业影响与未来趋势" class="headerlink" title="3.行业影响与未来趋势"></a>3.行业影响与未来趋势</h1><h2 id="1-行业影响："><a href="#1-行业影响：" class="headerlink" title="1.行业影响："></a>1.行业影响：</h2><ul>
<li><p>Sora的出现为视频领域带来了巨大的想象空间，突破了人类在专业能力上的限制，被誉为“世界模拟器”。</p>
</li>
<li><p>对于没有成熟运营、设计、策划团队的中小商家来说，Sora的智能生成可以实现内容生产的低成本化。</p>
</li>
</ul>
<h2 id="2-未来趋势："><a href="#2-未来趋势：" class="headerlink" title="2.未来趋势："></a>2.未来趋势：</h2><ul>
<li>随着业内追赶态势，市场上可能会出现更多类似Sora的模型和产品，促进用户采用率和需求的进一步增长。</li>
<li>Sora有望撬动AI多模态应用新热度，对传媒领域带来存量提质增效和新增应用场景。</li>
</ul>
<p>由此可见，Sora作为一款先进的视频生成模型，在技术架构、视频生成能力和应用范围等方面都展现了强大的潜力和优势。然而，它也面临着一些技术和监管上的挑战，需要持续优化和改进以实现更广泛的应用和更大的商业价值。</p>
<p><strong>那么我们不禁要问：Sora视频生成模型的技术细节和原理是什么？</strong></p>
<p>我认为，Sora视频生成模型是OpenAI于2024年2月16日发布的一项革命性技术，旨在通过文本提示、静态图像或现有视频生成或扩展高质量的视频内容。该模型在多个方面展现了显著的技术优势和创新。</p>
<h1 id="4-技术细节与原理"><a href="#4-技术细节与原理" class="headerlink" title="4.技术细节与原理"></a>4.技术细节与原理</h1><h2 id="1-扩散模型与Transformer架构"><a href="#1-扩散模型与Transformer架构" class="headerlink" title="1. 扩散模型与Transformer架构"></a>1. 扩散模型与Transformer架构</h2><p>Sora基于扩散模型（Diffusion Model），其核心机制是从一个看起来像静态噪声的视频开始，逐步去除噪声，最终生成清晰的视频。这种模型能够处理视频和图片中时空片段的潜在代码，并利用Transformer架构来捕捉前后文全局关系，从而实现每一帧图像的精确生成以及前后时空的一致性。</p>
<h2 id="2-视频补丁（Patch）"><a href="#2-视频补丁（Patch）" class="headerlink" title="2. 视频补丁（Patch）"></a>2. 视频补丁（Patch）</h2><p>Sora使用了“视频补丁”（Patch）这一高度可扩展且有效的表示形式。视频补丁将视频数据转化为较小的数据单元，类似于GPT中的token，这使得模型能够在不同类型的视频和图像上进行训练。这些补丁作为数据的有效提示，帮助模型更好地理解和生成复杂的视觉场景。</p>
<h2 id="3-大规模训练与语言理解"><a href="#3-大规模训练与语言理解" class="headerlink" title="3. 大规模训练与语言理解"></a>3. 大规模训练与语言理解</h2><p>Sora采用了大规模训练的方法，并结合了DALL·E 3中的重述技术和ChatGPT的大语言模型，以提高模型的语言理解能力。具体来说，Sora利用重新字幕技术生成高度描述性的字幕，并将简短的用户提示转换为详细的描述，从而生成与提示更匹配的高质量视频。</p>
<h2 id="4-DiT模型与解码器"><a href="#4-DiT模型与解码器" class="headerlink" title="4. DiT模型与解码器"></a>4. DiT模型与解码器</h2><p>Sora的核心技术之一是DiT（Denoising Diffusion Transformer）模型。该模型将视频压缩到低维潜在空间中，并将其分解为补丁，然后在低维空间中进行训练。通过逐步添加高斯噪声并学习如何逆向去除噪声，DiT模型能够生成新数据。最后，模型通过对应的解码器，将生成的元素映射回像素空间，完成视频生成任务。</p>
<h2 id="5-功能特点"><a href="#5-功能特点" class="headerlink" title="5. 功能特点"></a>5. 功能特点</h2><ul>
<li><strong>长时长视频生成</strong>：Sora可以一次性生成长达60秒的高保真视频，这在当前的AI视频生成领域中是一个重大突破。<br>复杂场景与细节：Sora能够生成包含精细复杂场景、生动角色表情以及复杂镜头运动的视频，确保三维空间中的人物和场景元素保持一致性。</li>
<li><strong>多模态输入</strong>：除了文本提示外，Sora还支持根据静态图像或现有视频进行扩展和生成。<br>灵活采样与全分辨率输出：Sora具有灵活采样和全分辨率输出的功能，可以快速创建不同设备的原始宽高比内容。</li>
</ul>
<h1 id="5-小结"><a href="#5-小结" class="headerlink" title="5.小结"></a>5.小结</h1><p>我觉得，Sora视频生成模型通过结合扩散模型、Transformer架构、视频补丁技术、大规模训练和语言理解能力等先进技术，实现了在视频生成领域的多项突破。</p>
<h1 id="6-Sora在处理复杂物理运动和逻辑关系时的具体局限性有哪些？"><a href="#6-Sora在处理复杂物理运动和逻辑关系时的具体局限性有哪些？" class="headerlink" title="6.Sora在处理复杂物理运动和逻辑关系时的具体局限性有哪些？"></a>6.Sora在处理复杂物理运动和逻辑关系时的具体局限性有哪些？</h1><h2 id="1-Sora在处理复杂物理运动和逻辑关系时存在以下具体局限性："><a href="#1-Sora在处理复杂物理运动和逻辑关系时存在以下具体局限性：" class="headerlink" title="1.Sora在处理复杂物理运动和逻辑关系时存在以下具体局限性："></a>1.Sora在处理复杂物理运动和逻辑关系时存在以下具体局限性：</h2><p><strong>1.无法准确模拟复杂物理现象</strong>：尽管Sora能够理解用户指令并生成视频，但其在模拟复杂场景中的物理特性方面仍存在困难。例如，它可能难以准确模拟玻璃杯倾倒、食物咬痕等复杂的物理运动，并且无法推演时间变化。<br><strong>2.混淆因果关系和空间细节</strong>：Sora有时会创造出不符合现实世界物理关系认知的画面，特别是在处理复杂、繁琐的物理运动时，可能无法准确模拟因果关系或推演时间变化。此外，该模型还存在混淆部分画面中文字表达的可能性，如广告牌标语不合逻辑或不成文字。<br><strong>3.难以精确描述随时间变化的事件</strong>：Sora可能无法准确模拟复杂场景的物理原理，并且可能无法理解因果关系，混淆提示的空间细节，难以精确描述随着时间推移发生的事件。<br><strong>4.对牛顿定律等物理规律的掌握不足</strong>：一些外部专家猜测，Sora很难将物理世界中的牛顿定律、湍流方程和量子学定理等规律一条一条在模型中显式罗列出来，这可能是由于神经网络模型的涌现之力所限。<br><strong>5.视频时长限制</strong>：Sora生成的视频时长有限制，最长只能生成60秒的视频，对于更长的视频片段，Sora会使用预训练模型进行处理。</p>
<h1 id="7-目前OpenAI如何解决Sora模型在数据隐私和版权方面的挑战？"><a href="#7-目前OpenAI如何解决Sora模型在数据隐私和版权方面的挑战？" class="headerlink" title="7.目前OpenAI如何解决Sora模型在数据隐私和版权方面的挑战？"></a>7.目前OpenAI如何解决Sora模型在数据隐私和版权方面的挑战？</h1><p>目前，OpenAI在解决Sora模型在数据隐私和版权方面的挑战方面采取了多种措施。首先，尽管有报道指出Sora模型的数据集可能包括未经许可获取的大量书籍及其他版权材料，引发了关于是否遵守知识产权法和数据采集伦理标准的争议，但OpenAI声称在训练Sora时使用了“公开可用”和“已许可”的内容。</p>
<p>为了应对这些挑战，OpenAI采取了一系列安全措施和对抗性测试。例如，在产品中使用Sora前，OpenAI承诺将由专家对模型进行对抗性测试，以评估其危害或风险，并核查并拒绝包含极端暴力、性骚扰、歧视、恐怖主义、仇恨图像、他人IP等文本输出的内容。此外，Sora内置的文本提示过滤器可以筛选发送给模型的所有提示，阻止对暴力、色情、仇恨言论以及名人肖像等敏感或不适当内容的请求。视频内容过滤器也能检查生成的视频帧，屏蔽违反OpenAI安全政策的内容。</p>
<p>虽然OpenAI已经采取了一些措施来缓解数据隐私和版权方面的挑战，但仍有公众对其处理敏感数据问题上的透明度和有效性表示担忧。</p>
<h1 id="8-Sora对广告业、电影预告片和短视频行业的具体影响有哪些实例？"><a href="#8-Sora对广告业、电影预告片和短视频行业的具体影响有哪些实例？" class="headerlink" title="8.Sora对广告业、电影预告片和短视频行业的具体影响有哪些实例？"></a>8.Sora对广告业、电影预告片和短视频行业的具体影响有哪些实例？</h1><h2 id="1-Sora对广告业、电影预告片和短视频行业的具体影响主要体现在以下几个方面："><a href="#1-Sora对广告业、电影预告片和短视频行业的具体影响主要体现在以下几个方面：" class="headerlink" title="1.Sora对广告业、电影预告片和短视频行业的具体影响主要体现在以下几个方面："></a>1.Sora对广告业、电影预告片和短视频行业的具体影响主要体现在以下几个方面：</h2><ul>
<li>降低视频制作成本和门槛：Sora能够帮助直播卖家高效地从长达数小时的直播中剪辑出亮点，并进行混剪和配音等处理，实现内容生产的低成本化。此外，Sora降低了视频制作的门槛和成本，将颠覆广告业、电影预告片、短视频行业和游戏等领域。</li>
<li>提高内容创作质量和效率：Sora的出现极大地提升了短视频的内容供给和创作质量，可能使短剧重心回归高质量剧本创作。它还能快速、准确地生成生动的现场视频，提高新闻报道的时效性。</li>
<li>个性化广告推送：在广告推送方面，Sora可以通过收集特定用户的偏好和兴趣来定制专属广告内容，提高顾客购买欲望和品牌忠诚度。</li>
<li>电影预告片和社交媒体宣传视频的制作：对于即将上映的电影或电视节目，使用Sora可以简化预告片或社交媒体宣传视频的制作过程，只需输入关键情节或场景的简短描述便能渲染出精选内容汇编的短视频，缩短制作周期的同时还能节省一定的制作成本。</li>
<li>促进技术创新和应用想象：Sora代表了AI赋能的新阶段，将为自学发展、人才培训、科学研究、产品研发等多个领域带来技术革新和应用想象。</li>
<li>改变内容产业的成本结构和资源支撑体系：短期内，Sora将直接改变很多内容产业的成本结构以及资源支撑体系，长期来看，其构建的基于三维物理世界来创造数字原型的强大引擎，将给一些产业带来深远影响。</li>
<li>可能引发行业内的就业变化：虽然Sora的问世可能会导致设计师、摄影师和后期制作岗位需求的大量减少，但对于拥有自身风格和调性的创作者来说，Sora只能起到辅助作用。同时，也有观点认为，尽管Sora带来了效率上的提升，但并不是说不需要人了，视频行业还有很多的环节不能被替代，比如创意。</li>
</ul>
<h1 id="9-未来市场上类似Sora的视频生成模型有哪些，它们的主要区别和优势是什么？"><a href="#9-未来市场上类似Sora的视频生成模型有哪些，它们的主要区别和优势是什么？" class="headerlink" title="9.未来市场上类似Sora的视频生成模型有哪些，它们的主要区别和优势是什么？"></a>9.未来市场上类似Sora的视频生成模型有哪些，它们的主要区别和优势是什么？</h1><h2 id="1-未来市场上类似Sora的视频生成模型主要有以下几款：Runway和Pika。这些模型与Sora的主要区别和优势如下："><a href="#1-未来市场上类似Sora的视频生成模型主要有以下几款：Runway和Pika。这些模型与Sora的主要区别和优势如下：" class="headerlink" title="1.未来市场上类似Sora的视频生成模型主要有以下几款：Runway和Pika。这些模型与Sora的主要区别和优势如下："></a>1.未来市场上类似Sora的视频生成模型主要有以下几款：Runway和Pika。这些模型与Sora的主要区别和优势如下：</h2><h3 id="1-视频时长："><a href="#1-视频时长：" class="headerlink" title="1.视频时长："></a>1.视频时长：</h3><ul>
<li>Sora：能够生成长达60秒的视频，这是目前市场上其他模型难以匹敌的。</li>
<li>Runway和Pika：虽然具体时长未明确提及，但它们在视频时长方面可能不如Sora长，通常只能生成5秒以内的短视频。</li>
</ul>
<h3 id="2-场景复杂度和逼真度："><a href="#2-场景复杂度和逼真度：" class="headerlink" title="2.场景复杂度和逼真度："></a>2.场景复杂度和逼真度：</h3><ul>
<li>Sora：可以生成主题精确、背景细节复杂的场景，并且视频效果逼真。此外，Sora还能够实现多角度镜头切换，保持前后一致性。</li>
<li>Runway和Pika：相比之下，它们在处理复杂场景和多角度镜头方面的能力可能较弱，无法生成如此高质量和细节丰富的视频。</li>
</ul>
<h3 id="3-物理规律的掌握："><a href="#3-物理规律的掌握：" class="headerlink" title="3.物理规律的掌握："></a>3.物理规律的掌握：</h3><ul>
<li>Sora：在对物理规律的掌握方面表现不俗，例如在汽车行驶视频中，汽车影子与车身始终契合。</li>
<li>Runway和Pika：这方面的能力可能不如Sora强，因为它们缺乏足够的数据标注和清洗工作量，导致模型在逻辑性和连续性方面的表现不如Sora。</li>
</ul>
<h3 id="4-多模态能力："><a href="#4-多模态能力：" class="headerlink" title="4.多模态能力："></a>4.多模态能力：</h3><ul>
<li>Sora：不仅支持文本生成视频，还具备图像生成视频等能力，并能执行各种图像和视频编辑任务。</li>
<li>Runway和Pika：虽然也具备一定的多模态能力，但在综合应用和扩展性方面可能不如Sora全面。</li>
</ul>
<h3 id="5-技术架构："><a href="#5-技术架构：" class="headerlink" title="5.技术架构："></a>5.技术架构：</h3><ul>
<li>Sora：采用转化器架构上的扩散模型，能够自主提取信息之间的关联并进行统一化重组，从而实现对文本信息的精准捕捉和渲染。</li>
<li>Runway和Pika：具体的技术架构未详细说明，但可能没有像Sora那样先进的技术支撑。</li>
</ul>
<h3 id="6-安全性和伦理风险："><a href="#6-安全性和伦理风险：" class="headerlink" title="6.安全性和伦理风险："></a>6.安全性和伦理风险：</h3><ul>
<li>Sora：尽管存在安全伦理风险，但其领先优势难以被打破，促使社交及内容平台与OpenAI更加紧密地合作。</li>
<li>Runway和Pika：同样面临安全性和伦理风险的问题，但可能在应对措施和风险管理方面不如Sora成熟。</li>
</ul>
<p>Sora在视频时长、场景复杂度、物理规律掌握、多模态能力和技术架构等方面均具有显著优势，而Runway和Pika则在这些方面略显不足。</p>
<hr>
<p>你好！我是<strong>进击的胖虎</strong>，一名关注AIGC技术的博主，如果你也喜欢我的文章就看看博主其他文章博主宝藏小站，开通正版GPT-4o教程在<a href="https://lcab-ljj.github.io/2024/08/07/Wildcard/"><strong>【重要】wildcard使用教程？如何用wildcard订阅国外服务？</strong></a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://lcab-ljj.github.io/2024/07/17/%E9%92%88%E5%B0%96%E5%AF%B9%E9%BA%A6%E8%8A%92/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/%5Cimages%5C%E5%A4%B4%E5%83%8F.jpg">
      <meta itemprop="name" content="进击的胖虎">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AIGC-platform">
      <meta itemprop="description" content="热爱AIGC技术的博主，为您带来优质内容">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | AIGC-platform">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/07/17/%E9%92%88%E5%B0%96%E5%AF%B9%E9%BA%A6%E8%8A%92/" class="post-title-link" itemprop="url">针尖对麦芒！Anthropic 推出 Claude Android 可实时翻译！</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-07-17 11:40:46" itemprop="dateCreated datePublished" datetime="2024-07-17T11:40:46+08:00">2024-07-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-07 10:09:17" itemprop="dateModified" datetime="2024-08-07T10:09:17+08:00">2024-08-07</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <blockquote>
<p><strong>【重要】推荐使用 Wildcard虚拟信用卡订阅GPT、Onlyfans等服务，价格更便宜、卡片有效期更长、支持的服务更多，具体教程请查看：<a href="https://lcab-ljj.github.io/2024/08/07/Wildcard/">Wildcard教程</a></strong></p>
</blockquote>
<hr>
<p><strong>Anthropic，作为OpenAI的强劲对手，于本周二正式推出了专为Android用户设计的Claude应用程序，</strong>旨在通过拓宽Claude的接入平台，吸引用户从ChatGPT转向其服务。这款Android应用承袭了五月问世的iOS版本的设计理念，用户无需支付任何费用即可体验到Anthropic顶尖AI模型——Claude 3.5 Sonnet的强大功能，并可选择升级为Anthropic的Pro或Team订阅计划以享受更多高级服务。</p>
<p><img src="/images/loading.png" data-original="/images/b9aeb9456bf5cea752748e69500fea5.png"></p>
<p>应用内，用户能够无缝同步跨设备的Claude对话记录，还能即时上传图片或文档，利用应用程序内置的实时图像分析功能进行深度处理。尤为值得一提的是，Claude Android版还集成了实时语言翻译特性，Anthropic寄望这一功能成为吸引用户频繁使用应用的强大诱因。此外，该应用还为企业客户量身打造了移动访问权限，使他们能够随时随地管理自己的Claude账户。</p>
<p><strong>然而，</strong>尽管Anthropic自信其AI技术能与OpenAI及Google的产品分庭抗礼，市场反应却揭示了其在吸引大众用户方面的挑战。回顾Claude iOS应用的初次亮相，其市场接受度较为温和，首周全球下载量仅为157,000次，相比之下，ChatGPT iOS应用在发布的前五天便实现了480,000次的安装量，这一数据对比凸显了Anthropic在消费者市场中的推广难题。</p>
<p><img src="/images/loading.png" data-original="http://eb118-file.cdn.bcebos.com/upload/28da87b7ec344be799292f9b99916a88_158473674.png"></p>
<hr>
<p>你好！我是<strong>进击的胖虎</strong>，一名关注AIGC技术的博主，如果你也喜欢我的文章就看看博主其他文章博主宝藏小站，开通正版GPT-4o教程在<a href="https://lcab-ljj.github.io/2024/08/07/Wildcard/"><strong>【重要】wildcard使用教程？如何用wildcard订阅国外服务？</strong></a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">进击的胖虎</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>






        <style>
            [bg-lazy] {
                background-image: none !important;
                background-color: #eee !important;
            }
        </style>
        <script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(r){r.imageLazyLoadSetting.processImages=t;var a=r.imageLazyLoadSetting.isSPA,n=r.imageLazyLoadSetting.preloadRatio||1,d=o();function o(){var t=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")),e=Array.prototype.slice.call(document.querySelectorAll("[bg-lazy]"));return t.concat(e)}function t(t){(a||t)&&(d=o());for(var e,i=0;i<d.length;i++)0<=(e=(e=d[i]).getBoundingClientRect()).bottom&&0<=e.left&&e.top<=(r.innerHeight*n||document.documentElement.clientHeight*n)&&function(){var t,e,a,n,o=d[i];e=function(){d=d.filter(function(t){return o!==t}),r.imageLazyLoadSetting.onImageLoaded&&r.imageLazyLoadSetting.onImageLoaded(o)},(t=o).dataset.loaded||(t.hasAttribute("bg-lazy")?(t.removeAttribute("bg-lazy"),e&&e()):(a=new Image,n=t.getAttribute("data-original"),a.onload=function(){t.src=n,t.removeAttribute("data-original"),t.setAttribute("data-loaded",!0),e&&e()},a.onerror=function(){t.removeAttribute("data-original"),t.setAttribute("data-loaded",!1),t.src=n},t.src!==n&&(a.src=n)))}()}function e(){clearTimeout(t.tId),t.tId=setTimeout(t,500)}t(),document.addEventListener("scroll",e),r.addEventListener("resize",e),r.addEventListener("orientationchange",e)}(this);</script></body>
</html>
